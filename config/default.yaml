defaults:
    - modality@_global_: state
    - override hydra/launcher: local
    - override hydra/output: local

# offline training
fraction: 1.0
train_iter: 500000

# encoder
encoder:
    arch: default
    pretrained: false

# environment
task: quadruped-run
action_repeat: 2
discount: 0.99
episode_length: 1000/${action_repeat}
train_steps: 500000/${action_repeat}

# planning
iterations: 6
num_samples: 512
num_elites: 64
mixture_coef: 0.05
min_std: 0.05
temperature: 0.5
momentum: 0.1

# learning
algorithm: 'tdmpc'
batch_size: 512
horizon: 5
reward_coef: 0.5
value_coef: 0.1
consistency_coef: 2
rho: 0.5
kappa: 0.1
lr: 1e-3
std_schedule: linear(0.5, ${min_std}, 25000)
horizon_schedule: linear(1, ${horizon}, 25000)
per_alpha: 0.6
per_beta: 0.4
grad_clip_norm: 10
seed_steps: 5000
update_freq: 2
tau: 0.01
steps_per_update: 1

# architecture
enc_dim: 256
mlp_dim: 512
latent_dim: 50

# wandb (fb)
wandb_project: tdmpc2
wandb_entity: nihansen

# wandb (personal)
# wandb_project: tdmpc
# wandb_entity: nicklashansen

# dirs
data_dir: /checkpoint/nihansen/data/tdmpc2
encoder_dir: /checkpoint/nihansen/data/tdmpc2/encoders

# misc
seed: 1
exp_name: default
eval_freq: 5000
eval_episodes: 10
save_video: false
save_model: false

# convenience
task_title: ???
device: ???
multitask: ???
num_tasks: ???
obs_shape: ???
action_shape: ???
action_dim: ???
demo: false

# cluster
hydra:
    job:
        name: ${exp_name}
    launcher:
        cpus_per_task: 10
        gpus_per_node: 1
        tasks_per_node: 1
        timeout_min: 180 #3000
        mem_gb: 32
        name: ${hydra.job.name}
        # array_parallelism: 256
        submitit_folder: ${hydra.sweep.dir}/.submitit/%j
