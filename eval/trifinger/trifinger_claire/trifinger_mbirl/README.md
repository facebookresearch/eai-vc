# Model-based IRL for the TriFinger platform
Code adapated from [the LearningtoLearn respository](https://github.com/facebookresearch/LearningToLearn/tree/main/mbirl).

## Loading and pre-processing training and test data

Training script takes a `.pth` (pytorch) file that contains pre-processed demo info for training and testing. This file is generated by running `trifinger_mbirl/preload_trajs.py`. This script does the following:
- read raw observations from demo.npz files and re-formatting them
- downsamples full trajectories
- computes r3m embeddings on image observations

For ease-of-testing, I've uploaded a `.pth` file which contains 1 training and 1 test trajectory to this repo, [here].(https://github.com/fmeier/trifinger_claire/blob/main/demos/preloaded_demos/demos_d-1_train-1_test-1_scale-100.pth)

The script `preload_trajs.py` can be run with args that specify the difficulty levels to include, and the number of training demos and test demos to include from each difficulty level. Running `preload_trajs.py` will save a `.pth` (pytorch) file with a list of training trajectories and list of test trajectories to the `demos/preloaded_demos/` trajectory. 

For example, pre-load 10 training trajectories and 1 test trajectory for difficulty 1, which will write the file `demos/preloaded_demos/demos_d-1_train-10_test-1_scale-100.pth`. This file is what weâ€™ll pass into our training scripts.

```
python trifinger_mbirl/preload_trajs.py --difficulty 1 --n_train 10 --n_test 1
```

## Launch training

### Single runs

Run `trifinger_mbirl/train.py`, setting hydra config parameters according to the desired algorithm and corresponding parameters. Running single runs of `train.py` will save all log and output files in the default hydra output directory for single runs:

```outputs/<DATE-OF-RUN>/<TIMESTAMP-OF-RUN>/```

Some example commands for various algorithms:

- MBIRL with simple fingertip-only forward model (default config):
    
    ```
    python trifinger_mbirl/train.py
    ```
    
- MBIRL with learned forward model where object state is object position
    
    ```
    python trifinger_mbirl/train.py algo.mpc_type=ftpos_obj_learned_only algo.mpc_forward_model_ckpt=trifinger_mbirl/forward_models/runs/phase2_model_nt-100_ost-pos_train-all/epoch_3000_ckpt.pth
    ```
    
- MBIRL with learned forward model where object state is R3M embeddings
    
    ```
    python trifinger_mbirl/train.py algo.mpc_type=ftpos_obj_learned_only algo.mpc_forward_model_ckpt=trifinger_mbirl/forward_models/runs/phase2_model_nt-100_ost-img_r3m/epoch_5000_ckpt.pth
    ```
    
- BC with object position and fingertip positions defined relative to object goal position (`bc.obs_type=goal_rel`)
    
    ```
    python trifinger_mbirl/train.py algo=bc algo.obs_type=goal_rel
    ```
    
- BC using R3M embeddings in observation
    
    ```
    python trifinger_mbirl/train.py algo=bc algo.obs_type=img_r3m
    ```
    

### Launching runs as slurm jobs (with submitit launcher)

#### Defining experiment parameters: `<exp-name>/.yaml`

A single `<EXP_NAME>.yaml` file, saved under the directory `trifinger_mbirl/configs/experiments/`, defines the experiment name and the parameters to sweep over for an experiment. To sweep over parameters, we use the built-in hydra sweeper. For parameters you want to sweep over, you can specify a list of values, or use [other hydra syntax options](https://hydra.cc/docs/advanced/override_grammar/extended/) to specify ranges/values to sweep over.

Here is an example experiment config file, [`test.yaml`](https://github.com/fmeier/trifinger_claire/blob/main/trifinger_mbirl/configs/experiment/test.yaml), that will launch 4 jobs, which will sweep over the specified values for `cost_lr` and `action_lr`.  **NOTE**: Any parameters not specified in the `.yaml` will be set to their default values.

```
# @package _global_
hydra:
  sweeper:
    params:
        demo_path: demos/preloaded_demos/demos_d-1_train-1_test-1_scale-100.pth
        algo.cost_lr: 1e-2, 1e-3
        algo.action_lr: 1e-2, 1e-3
        algo.mpc_type: ftpos
        algo.cost_state: ftpos
```

#### Defining slurm launcher configs

Launch slurm jobs with the [SubmitIt Launcher plugin](https://hydra.cc/docs/plugins/submitit_launcher/). SubmitIt can either launch jobs locally, for testing, or launch jobs to slurm. For either launcher, we want to be able to specify custom configs, such as number of CPUs per task, and timelimits. These custom launcher config files are saved under [`trifinger_mbirl/configs/hydra/launcher/`](https://github.com/fmeier/trifinger_claire/tree/main/trifinger_mbirl/configs/hydra/launcher). Any parameters not specified in these config files will be set to their default values.

#### Launching jobs with SubmitIt launcher

Here are two example commands for launching the `test.yaml` experiment, both locally and on the cluster. In our command, we need to use the `--multirun` arg, which tells hydra to run multiple configurations, specify an experiment with the the `+experiment=<EXP_NAME>` arg, and specify a launcher config file with the `hydra/launcher` arg. Logs for each run will be saved in `multirun/<EXP-DATE>/exp-<EXP_NAME>-<TIMESTAMP>/<RUN_NUMBER>/`.

- Locally:

```
python trifinger_mbirl/train.py --multirun +experiment=test hydra/launcher=custom_submitit_local
```

- On cluster, via slurm:

```
python trifinger_mbirl/train.py --multirun +experiment=test hydra/launcher=custom_submitit_slurm
```

Use the command `squeue -u <USERNAME>` to see verify that your slurm jobs have been launched.


### Hydra config structure and descriptions for all parameters

Hydra config files are in `trifinger_mbirl/configs/`

- Default config file is `config.yaml`
    
    Description of parameters
    
    ```yaml
    defaults:
        - _self_
        - algo: # Default algorithm. Choices = [mbirl, bc]
    
    demo_path: # path/to/preloaded_demo.pth (Default path is 10 training trajectories, 1 test trajectory)
    log_dir  : # path/to/log_dir
    no_wandb : # If True, log experiment to wandb
    run_id   : # Run id (By default set to ${hydra:job.num})
    exp_id   : # Experiment name (By default set to ${experiment.name} defined in experiment.yaml)
    ```
    
- Algorithm (mbirl, bc) specific configs in `trifinger_mbirl/configs/algos/`
    - `mbirl.yaml`
        
        ```yaml
        name                  : # Don't change. Algorithm name, set to mbirl  
        cost_type             : # Cost type. Choices = [Weighted, TimeDep, RBF, MPTimeDep, Traj]
        cost_lr               : # Cost function learning rate
        action_lr             : # Action/policy learning rate
        n_inner_iter          : # Number of inner iterations
        cost_state            : # State to use in cost function. Choices = [ftpos, obj, ftpos_obj]
        irl_loss_state        : # State to use in IRL loss function. Choices = [ftpos, obj, ftpos_obj]
        rbf_kernels           : # Number of RBF kernels
        rbf_width             : # RBF kernel width
        n_outer_iter          : # Number of outer iterations
        n_epoch_every_log     : # Save checkpoints and plots every this many epochs 
        mpc_type              : # MPC type. Choices = [ftpos, ftpos_obj_two_phase, ftpos_obj_learned_only]
        mpc_forward_model_ckpt: # path/to/forward_model_ckpt.pth (Set only if mpc_type in [ftpos_obj_two_phase, ftpos_obj_learned_only])
        ```
        
    - `bc.yaml`
        
        ```yaml
        name             : Don't change. Algorithm name, set to bc
        lr               : Learning rate
        obs_type         : Observation type to use for bc. Choices = [goal_none, goal_rel, img_r3m]
        n_outer_iter     : Number of training epochs
        n_epoch_every_log: Save checkpoints every this many epochs
        ```

## Plot learned cost weights

So far, this script only supports plotting the weights for the multi-phase cost. 

```
python trifinger_mbirl/plot_learned_cost.py <PATH/TO/EXP/log.pth> <-s SAVE FIG TO EXP DIR>
```

Example usage:
```
python trifinger_mbirl/plot_learned_cost.py /Users/clairelchen/projects/trifinger_claire/trifinger_mbirl/logs/runs/exp_NOID_al-0p01_cl-0p01_ct-MPTimeDep_ils-100_nii-50_noi-1500_rk-5_rw-2_th-17/log.pth -s
```
