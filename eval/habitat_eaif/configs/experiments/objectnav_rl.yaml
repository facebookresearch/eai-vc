VERBOSE: True
TRAINER_NAME: "mddppo"
ENV_NAME: "SimpleRLEnv"
SENSORS: ["RGB_SENSOR"]

SIMULATOR_GPU_ID: 0
TORCH_GPU_ID: 0

VIDEO_OPTION: []
VIDEO_DIR: ${hydra:sweep.dir}/video
TENSORBOARD_DIR: ${hydra:sweep.dir}/logs
EVAL_CKPT_PATH_DIR: ${hydra:sweep.dir}/checkpoints
CHECKPOINT_FOLDER: ${hydra:sweep.dir}/checkpoints
LOG_DIR: ${hydra:sweep.dir}/logs
LOG_FILE: ${hydra:sweep.dir}/train.log

TEST_EPISODE_COUNT: -1

NUM_ENVIRONMENTS: 12
LOG_INTERVAL: 100
NUM_CHECKPOINTS: 100
NUM_UPDATES: -1
TOTAL_NUM_STEPS: 200e6
FORCE_TORCH_SINGLE_THREADED: True

EVAL:
  SPLIT: "val"
  USE_CKPT_CONFIG: True
  EVAL_FREQ: 5

RL:
  REWARD_MEASURE: "simple_reward"
  SUCCESS_MEASURE: "success"

  POLICY:
    name: "EAIPolicy"
    input_image_size: 256
    hidden_size: 512
    rnn_type: "LSTM"
    num_recurrent_layers: 2
    use_augmentations: False
    use_augmentations_test_time: False
    freeze_batchnorm: True
    freeze_backbone: True
    global_pool: False
    use_cls: False

  PPO:
    # ppo params
    clip_param: 0.2
    ppo_epoch: 4
    num_mini_batch: 2
    value_loss_coef: 0.5
    entropy_coef: 0.01
    lr: 2.5e-4
    encoder_lr: 1.5e-6
    wd: 1e-6
    eps: 1e-5
    max_grad_norm: 0.2
    num_steps: 64
    use_gae: True
    use_linear_lr_decay: False
    use_linear_clip_decay: False
    gamma: 0.99
    tau: 0.95
    reward_window_size: 50
    use_normalized_advantage: False
    hidden_size: 512

  DDPPO:
    sync_frac: 0.6
    distrib_backend: "NCCL"

    # Model parameters
    backbone: resnet50
    rnn_type: LSTM
    num_recurrent_layers: 2
