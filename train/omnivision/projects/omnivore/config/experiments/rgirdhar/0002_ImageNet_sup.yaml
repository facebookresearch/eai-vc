# @package _global_

data_module:
  _target_: omnivision.data_module.base_data_module.BaseDataModule
  train:
    dataset:
      _target_: omnivore.data.path_dataset.ImagePathDataset
      path_file_list:
        - manifold://omnivore/tree/datasets/imagenet_1k_everstore_meta/train_images.npy
      label_file_list:
        - manifold://omnivore/tree/datasets/imagenet_1k_everstore_meta/train_labels.npy
      new_prefix: memcache_everstore://fair/cv/
      transforms:
        - _target_: omnivore.data.transforms.transform_wrappers.VisionTransform
          base_transform:
            _target_: torchvision.transforms.Compose
            transforms:
              - _target_: torchvision.transforms.RandomResizedCrop
                size: 224
                interpolation: 3
              - _target_: torchvision.transforms.RandomHorizontalFlip
              - _target_: omnivore.data.transforms.rand_auto_aug.RandAugment  # Essentially autoagument rand-m9-mstd0.5-inc1
                magnitude: 9
                magnitude_std: 0.5
                increasing_severity: True
              - _target_: torchvision.transforms.ColorJitter
                brightness: 0.4
                contrast: 0.4
                saturation: 0.4
                hue: 0.4
              - _target_: torchvision.transforms.ToTensor
              - _target_: torchvision.transforms.RandomErasing
                p: .25
              - _target_: torchvision.transforms.Normalize
                mean: [0.485, 0.456, 0.406]
                std: [0.229, 0.224, 0.225]
    shuffle: True
    batch_size: 64
    num_workers: 8
    pin_memory: True
    drop_last: True
    collate_fn:
      _target_: omnivore.data.collators.cutmixup_collator.CutMixUpCollator
      mixup_alpha: 0.8 # mixup alpha value, mixup is active if > 0.
      cutmix_alpha: 1.0 # cutmix alpha value, cutmix is active if > 0.
      prob: 1.0 # probability of applying mixup or cutmix per batch or element
      switch_prob: 0.5 # probability of switching to cutmix instead of mixup when both are active
      mode: batch # how to apply mixup/cutmix params (per 'batch', 'pair' (pair of elements), 'elem' (element)
      correct_lam: True # apply lambda correction when cutmix bbox clipped by image borders
      label_smoothing: 0.1 # apply label smoothing to the mixed target tensor
      num_classes: 1000 # number of classes for target
    worker_init_fn: NULL
  val:
    dataset:
      _target_: omnivore.data.path_dataset.ImagePathDataset
      path_file_list:
        - manifold://omnivore/tree/datasets/imagenet_1k_everstore_meta/val_images.npy
      label_file_list:
        - manifold://omnivore/tree/datasets/imagenet_1k_everstore_meta/val_labels.npy
      new_prefix: memcache_everstore://fair/cv/
      transforms:
        - _target_: omnivore.data.transforms.transform_wrappers.VisionTransform
          base_transform:
            _target_: torchvision.transforms.Compose
            transforms:
              - _target_: torchvision.transforms.Resize
                size: 224
                interpolation: 3
              - _target_: torchvision.transforms.CenterCrop
                size: 224
              - _target_: torchvision.transforms.ToTensor
              - _target_: torchvision.transforms.Normalize
                mean: [0.485, 0.456, 0.406]
                std: [0.229, 0.224, 0.225]
    shuffle: False
    batch_size: 64
    num_workers: 8
    pin_memory: True
    drop_last: True
    collate_fn:
      _target_: omnivore.data.api.DefaultOmnivoreCollator
    worker_init_fn: NULL
lightning_module:
  _target_: omnivore.lightning_module.omnivore_lightning_module.OmnivoreLightningModule
  model:
    _target_: torch.nn.Sequential
    _args_:
      - _target_: omnivore.models.swin_transformer.SwinTransformer3D
        pretrained: NULL
        pretrained2d: False
        patch_size: [1, 4, 4]
        embed_dim: 96
        depths: [2, 2, 6, 2]
        num_heads: [3, 6, 12, 24]
        window_size: [1, 7, 7]
        mlp_ratio: 4.
        qkv_bias: True
        qk_scale: NULL
        drop_rate: 0.
        attn_drop_rate: 0.
        drop_path_rate: 0.2
        patch_norm: True
      - _target_: torch.nn.Linear
        in_features: 768  # 8 * 96
        out_features: 1000
  optim:
    optimizer:
      _target_: torch.optim.AdamW
    options:
      lr:
        - scheduler:
            _target_: fvcore.common.param_scheduler.CompositeParamScheduler
            schedulers:
              - _target_: fvcore.common.param_scheduler.LinearParamScheduler
                start_value: 10e-7
                end_value: 10e-4
              - _target_: fvcore.common.param_scheduler.CosineParamScheduler
                start_value: 10e-4
                end_value: 10e-6
            lengths: [0.07, 0.93]
            interval_scaling: ['rescaled', 'rescaled']
      weight_decay:
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.05
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.0
          param_names: ['*.bias']
          module_cls_names: ['torch.nn.LayerNorm']
  meters:
    train:
      accuracy_top1:
        _target_: omnivision.meters.accuracy_meter.AccuracyMeter
        top_k: 1
      accuracy_top5:
        _target_: omnivision.meters.accuracy_meter.AccuracyMeter
        top_k: 5
    val:
      accuracy_top1:
        _target_: omnivision.meters.accuracy_meter.AccuracyMeter
        top_k: 1
      accuracy_top5:
        _target_: omnivision.meters.accuracy_meter.AccuracyMeter
        top_k: 5
  loss:
    _target_: torch.nn.CrossEntropyLoss

lightning_trainer:
  _target_: pytorch_lightning.Trainer
  num_nodes: ${trainer.num_nodes}
  gpus: ${trainer.gpus_per_node}
  sync_batchnorm: False
  replace_sampler_ddp: False
  #limit_train_batches: 2
  #limit_val_batches: 2
  #limit_test_batches: 0
  max_epochs: 300
  accelerator: gpu
  strategy: ddp

trainer:
  num_nodes: 4
  gpus_per_node: 8
  mode: train
  strategy: ddp

logger:
  _target_: pytorch_lightning.loggers.TensorBoardLogger
  save_dir: ???
  name: default
  version: null

submitit_conf:
  log_save_dir: null
  name: "ptv_trainer_job"
  time: "72:00:00"
  cpus_per_task: 10
  partition: "devlab"
  mem: "470GB"
  constraint: "volta32gb"
  mode: "prod"
  use_cluster: False

