# @package _global_
# Modified from omnivision/projects/omnivore/config/experiments/kalyanv/no_lightning/v0.1/0016_mae_vitbase_concat.yaml


base_batchsize_per_replica: 32
patch_size: [2, 16, 16]

trainer:
  _target_: omnivore.trainer.omnivision_trainer.OmnivisionTrainer
  max_epochs: 800
  accelerator: cuda
  seed_value: 123
  mode: train

  data:
    train:
      _target_: omnivore.data.concat_dataset.ConcatDataset
      max_steps: sum
      repeat_factors:
        - 1.0
      datasets:
      - _target_: omnivore.data.torch_dataset.TorchDataset
        dataset:
          _target_: omnivore.data.path_dataset.ImagePathDataset
          path_file_list:
            - /checkpoint/maksymets/eaif/datasets/hm3d+gibson.npy
            - /srv/flash1/amajumdar36/image-datasets/hm3d+gibson/v1/train/path_file_list.npy
          transforms:
            - _target_: omnivore.data.transforms.transform_wrappers.VisionTransform
              base_transform:
                _target_: torchvision.transforms.Compose
                transforms:
                  - _target_: torchvision.transforms.RandomResizedCrop
                    size: 224
                    scale: [0.2, 1.0]
                    interpolation: 3
                  - _target_: torchvision.transforms.RandomHorizontalFlip
                    p: 0.5
                  - _target_: torchvision.transforms.ToTensor
                  - _target_: torchvision.transforms.Normalize
                    mean: [0.485, 0.456, 0.406]
                    std: [0.229, 0.224, 0.225]
            - _target_: omnivore.data.transforms.transform_wrappers.MaskingTransform
              masking_object:
                _target_: omnivore.data.transforms.mask_image_modeling.MaskImageModeling
                pred_ratio: 0.75
                pred_ratio_var: 0.0
                pred_shape:
                  _target_: omnivore.data.transforms.mask_image_modeling.RandMasking
                patch_size: ${trainer.model.trunk.patch_size}
        shuffle: True
        batch_size: ${base_batchsize_per_replica}
        num_workers: 6
        pin_memory: True
        drop_last: True
        collate_fn:
          _target_: omnivore.data.api.DefaultOmnivoreCollator
          output_key: ssv2
        worker_init_fn: NULL
    val: NULL

  model:
    _target_: omnivision.model.model_wrappers.MIMOHeadWrapper
    handle_list_inputs: True
    trunk:
      _target_: omnivore.models.vision_transformer.VisionTransformer
      img_size:
        - 3
        - 2
        - 224
        - 224
      embed_dim: 768
      depth: 12
      patch_size: [2, 16, 16]
      classifier_feature: global_pool
      drop_path_rate: 0.0
      use_cls_token: False
      patch_embed_type: tmae
      patch_embed_params_list:
        - _target_: omnivore.models.PadIm2Video
          pad_type: repeat
          ntimes: 2
        - _target_: torch.nn.Conv3d
          in_channels: 3
          out_channels: 768
          kernel_size: ${patch_size}
          stride: ${patch_size}
      attn_target:
        _target_: omnivore.models.vision_transformer.Attention
        _partial_: True
        num_heads: 12
        proj_drop: 0
        qk_scale: NULL
        qkv_bias: True
        attn_drop: 0
      learnable_pos_embed: False  # Use sinusoidal positional encoding
      masked_image_modeling: True
      patch_dropping: True
      decoder:
        _target_: omnivore.models.vision_transformer.Decoder
        _partial_: True
        embed_dim: ${trainer.model.trunk.embed_dim}
        decoder_depth: 4
        decoder_embed_dim: 384
        learnable_pos_embed: False  # Use sinusoidal positional encoding
        attn_target:
          _target_: omnivore.models.vision_transformer.Attention
          _partial_: True
          num_heads: 16
          proj_drop: 0
          qk_scale: NULL
          qkv_bias: True
          attn_drop: 0
    heads:
      - head:
          _target_: omnivore.models.heads.mae_head.MAEHead
          in_features: ${trainer.model.trunk.decoder.decoder_embed_dim}
          out_features: ${times:${times:${times:${trainer.model.trunk.img_size.0},${trainer.model.trunk.patch_size.0}},${trainer.model.trunk.patch_size.1}},${trainer.model.trunk.patch_size.2}}
        input_key: NULL
        output_key: NULL
        fork_module: ""
    trunk_fields:
      - input_key: NULL
        args: ["vision"]
        kwargs: {"mask": "mask"}
  optim:
    optimizer:
      _target_: torch.optim.AdamW
      betas: [0.9, 0.95]
    options:
      lr:
        - scheduler:
            _target_: fvcore.common.param_scheduler.CompositeParamScheduler
            schedulers:
              - _target_: fvcore.common.param_scheduler.LinearParamScheduler
                start_value: 1e-6
                end_value: 1.6e-3  # 8e-4 in orig config
              - _target_: fvcore.common.param_scheduler.CosineParamScheduler
                start_value: ${..0.end_value}
                end_value: 0.0
            lengths: [0.05, 0.95]  # warm for 40 epochs
            interval_scaling: ['rescaled', 'fixed']
      weight_decay:
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.05
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.0
          param_names:
             - '*.bias'
          module_cls_names: ['torch.nn.LayerNorm']
  meters: NULL
  loss:
    ssv2:
      _target_: omnivore.losses.mae_loss.MAELoss
      norm_pix_loss: True
      norm_pix_per_channel: True
      patch_size: ${trainer.model.trunk.patch_size}
      unnormalize_img:
        - [0.485, 0.456, 0.406]
        - [0.229, 0.224, 0.225]
      pad_object: ${trainer.model.trunk.patch_embed_params_list.0}

  logging:
    tensorboard_writer:
      _target_: omnivore.logger.make_tensorboard_logger
      log_dir:  ${launcher.experiment_log_dir}/tensorboard
      flush_secs: 120
      wandb: true
    log_dir: ${launcher.experiment_log_dir}/logs
    log_freq: 10

  checkpoint:
    save_dir: ${launcher.experiment_log_dir}/checkpoints
    save_freq: 0 # 0 only last checkpoint is saved.


launcher:
  num_nodes: 8
  gpus_per_node: 8
  experiment_log_dir: ???

submitit:
  name: "omnivision_omnivore"
  timeout_hour: 72
  cpus_per_task: 10
  partition: "learnlab"
  mem: "470GB"
  constraints: "volta32gb"
  use_cluster: True

  port_range: [10000, 65000]
