# @package _global_

lightning_module:
  _target_: omnivore.lightning_module.language_vision_lightning_module.LanguageVisionModule
  tokenizer:
    _target_: slip.tokenizer.SimpleTokenizer
    bpe_path_list:
    - /checkpoint/kalyanv/data/slip/bpe_simple_vocab_16e6.txt.gz
    - manifold://omnivore/tree/datasets/yfcc100m/meta_data/yfcc_meta_data/bpe_simple_vocab_16e6.txt.gz
  dataset_name: imagenet
  labels:
    _target_: omnivore.utils.data.load_file_from_list
    file_list:
    - /checkpoint/kalyanv/data/slip/labels.json
    - manifold://omnivore/tree/datasets/yfcc100m/meta_data/yfcc_meta_data/labels.json
  templates:
    _target_: omnivore.utils.data.load_file_from_list
    file_list:
    - /checkpoint/kalyanv/data/slip/templates.json
    - manifold://omnivore/tree/datasets/yfcc100m/meta_data/yfcc_meta_data/templates.json
  meters:
    val:
      accuracy_top1:
        _target_: omnivision.meters.accuracy_meter.AccuracyMeter
        top_k: 1
      accuracy_top5:
        _target_: omnivision.meters.accuracy_meter.AccuracyMeter
        top_k: 5
    test:
      accuracy_top1:
        _target_: omnivision.meters.accuracy_meter.AccuracyMeter
        top_k: 1
      accuracy_top5:
        _target_: omnivision.meters.accuracy_meter.AccuracyMeter
        top_k: 5
  loss:
    _target_: slip.losses.CLIPLoss

lightning_trainer:
  _target_: pytorch_lightning.Trainer
  num_nodes: ${launcher.num_nodes}
  gpus: ${launcher.gpus_per_node}
  log_gpu_memory: null
  sync_batchnorm: False
  replace_sampler_ddp: False
  max_epochs: 25
  accelerator: ${launcher.accelerator}
  strategy: ${launcher.strategy}
  precision: 16
  benchmark: True

launcher:
  num_nodes: 8
  gpus_per_node: 8
  mode: train
  accelerator: gpu
  strategy: ddp

submitit:
  name: clip_base
  partition: learnlab
  time: "72:00:00"
  mem: "470GB"
  constraints: "volta32gb"
  use_cluster: True
  cpus_per_task: 10
