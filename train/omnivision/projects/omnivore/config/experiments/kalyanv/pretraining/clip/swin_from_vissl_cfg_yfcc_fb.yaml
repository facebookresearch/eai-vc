# @package _global_

defaults:
  - /experiments/kalyanv/pretraining/clip/base_configs/base_clip.yaml
  - /experiments/kalyanv/pretraining/clip/base_configs/data/yfcc_fb.yaml
  - _self_

data_module:
  train:
    batch_size: 256
    num_workers: 10

lightning_module:
  model:
    _target_: slip.models.CLIP
    embed_dim: 512
    vision_width: 1024
    context_length: 77
    vocab_size: 49408
    transformer_width: 512
    transformer_heads: 8
    transformer_layers: 12
    freeze_vision: True
    vision_model:
      _target_: omnivision.model.checkpoint_utils.load_state_dict_into_model
      state_dict:
        _target_: omnivision.model.checkpoint_utils.load_vissl_checkpoint_trunk_only
        path_list:
          - manifold://omnivore/tree/imisra/configs/experiments/pretrain/ibot/39_ibot_swinB_LS_12crops_fz5ep_mim70_tw50_wdcos_ep300_wd.sweep/0/checkpoint.torch
      model:
        _target_: omnivision.model.checkpoint_utils.build_trunk_from_vissl_config
        config_file_path: manifold://omnivore/tree/imisra/configs/experiments/pretrain/ibot/39_ibot_swinB_LS_12crops_fz5ep_mim70_tw50_wdcos_ep300_wd.sweep/0/train_config.yaml
        in_project_dir: False
  optim:
    optimizer:
      _target_: torch.optim.AdamW
      betas: [0.9,0.98]
      eps: 1e-8
    options:
      lr:
        - scheduler:
            _target_: fvcore.common.param_scheduler.CompositeParamScheduler
            schedulers:
              - _target_: fvcore.common.param_scheduler.LinearParamScheduler
                start_value: 1e-6
                end_value: 1e-3
              - _target_: fvcore.common.param_scheduler.CosineParamScheduler
                start_value: 1e-3
                end_value: 1e-5
            lengths: [0.04, 0.96]
            interval_scaling: ['rescaled', 'rescaled']
      weight_decay:
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.1
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.0
          param_names:
            - 'logit_scale'
            - '*bias*'
            - '*ln*'
            - 'visual*norm*'
          module_cls_names: ['torch.nn.LayerNorm']
