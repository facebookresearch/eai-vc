# @package _global_

defaults:
  - /experiments/kalyanv/pretraining/clip/base_configs/base_clip.yaml
  - /experiments/kalyanv/pretraining/clip/base_configs/data/cmd_55m_fair.yaml
  - _self_

data_module:
  train:
    batch_size: 256
    num_workers: 10

lightning_module:
  model:
    _target_: slip.models.CLIP_IBOT_B16_Frozen
  optim:
    optimizer:
      _target_: torch.optim.AdamW
      betas: [0.9,0.98]
      eps: 1e-8
    options:
      lr:
        - scheduler:
            _target_: fvcore.common.param_scheduler.CompositeParamScheduler
            schedulers:
              - _target_: fvcore.common.param_scheduler.LinearParamScheduler
                start_value: 1e-6
                end_value: 2e-3
              - _target_: fvcore.common.param_scheduler.CosineParamScheduler
                start_value: 2e-3
                end_value: 1e-5
            lengths: [0.04, 0.96]
            interval_scaling: ['rescaled', 'rescaled']
      weight_decay:
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.1
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.0
          param_names:
            - 'logit_scale'
            - 'visual.blocks.[0,1,2,3,4,5,6,7,8,9,10,11].norm1.weight'
            - 'visual.blocks.[0,1,2,3,4,5,6,7,8,9,10,11].norm2.weight'
            - '*bias*'
            - '*ln*'
            - 'visual.norm.weight'
          module_cls_names: ['torch.nn.LayerNorm']

lightning_trainer:
  max_epochs: 10
