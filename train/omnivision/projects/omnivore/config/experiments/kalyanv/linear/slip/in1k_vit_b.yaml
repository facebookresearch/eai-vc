# @package _global_

data_module:
  _target_: omnivision.data_module.base_data_module.BaseDataModule
  val:
    dataset:
      _target_: omnivore.data.path_dataset.ImagePathDataset
      path_file_list: 
        - /checkpoint/imisra/datasets/in1k_disk/val_images_global.npy
      label_file_list: 
        - /checkpoint/imisra/datasets/in1k_disk/val_labels.npy
      # name: imagenet1k_val
      transform:
        _target_: torchvision.transforms.Compose
        transforms:
          - _target_: torchvision.transforms.Resize
            size: 256
          - _target_: torchvision.transforms.CenterCrop
            size: 224
          - _target_: torchvision.transforms.ToTensor
          - _target_: torchvision.transforms.Normalize
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
    shuffle: False
    batch_size: 256
    num_workers: 8
    pin_memory: True
    drop_last: False
    collate_fn:
      _target_: omnivore.data.api.DefaultOmnivoreCollator
    worker_init_fn: NULL

  test:
    dataset:
      _target_: omnivore.data.path_dataset.ImagePathDataset
      path_file_list: 
        - /checkpoint/imisra/datasets/in1k_disk/val_images_global.npy
      label_file_list: 
        - /checkpoint/imisra/datasets/in1k_disk/val_labels.npy
      # name: imagenet1k_val
      transform:
        _target_: torchvision.transforms.Compose
        transforms:
          - _target_: torchvision.transforms.Resize
            size: 256
          - _target_: torchvision.transforms.CenterCrop
            size: 224
          - _target_: torchvision.transforms.ToTensor
          - _target_: torchvision.transforms.Normalize
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
    shuffle: False
    batch_size: 256
    num_workers: 8
    pin_memory: True
    drop_last: False
    collate_fn:
      _target_: omnivore.data.api.DefaultOmnivoreCollator
    worker_init_fn: NULL

  train:
    dataset:
      _target_: omnivore.data.path_dataset.ImagePathDataset
      path_file_list: 
        - /checkpoint/imisra/datasets/in1k_disk/train_images_global.npy
      label_file_list: 
        - /checkpoint/imisra/datasets/in1k_disk/train_labels.npy
      # name: imagenet1k_val
      transform:
        _target_: torchvision.transforms.Compose
        transforms:
          - _target_: torchvision.transforms.RandomResizedCrop
            size: 224
          - _target_: torchvision.transforms.RandomHorizontalFlip
          - _target_: torchvision.transforms.ToTensor
          - _target_: torchvision.transforms.Normalize
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
    shuffle: False
    batch_size: 128
    num_workers: 8
    pin_memory: True
    drop_last: False
    collate_fn:
      _target_: omnivore.data.api.DefaultOmnivoreCollator
    worker_init_fn: NULL

lightning_module:
  _target_: omnivore.lightning_module.omnivore_lightning_module.OmnivoreLightningModule
  # model:
  #   _target_: slip.models.SingleHeadWrapper
  #   finetune_trunk: false
  #   trunk:
  #     _target_: slip.models.load_vision_model_from_lv_checkpoint
  #     ckpt_path: /checkpoint/kalyanv/experiments/slip/53894928/checkpoint_best.pt
  #   head_finetune:
  #     _target_: slip.models.consturct_simple_finetune_linear_head
  #     in_features: 512
  #     out_features: 1000
  model:
    _target_: slip.models.create_timm_finetuneModel_from_ckpt
    num_classes: 1000
    ckpt_path: /checkpoint/kalyanv/experiments/slip/53894928/checkpoint_best.pt
    arch: vit_base_patch16_224
  meters:
    val:
      accuracy_top1:
        _target_: omnivision.meters.accuracy_meter.AccuracyMeter
        top_k: 1
      accuracy_top5:
        _target_: omnivision.meters.accuracy_meter.AccuracyMeter
        top_k: 5
    train:
      accuracy_top1:
        _target_: omnivision.meters.accuracy_meter.AccuracyMeter
        top_k: 1
      accuracy_top5:
        _target_: omnivision.meters.accuracy_meter.AccuracyMeter
        top_k: 5
    test:
      accuracy_top1:
        _target_: omnivision.meters.accuracy_meter.AccuracyMeter
        top_k: 1
      accuracy_top5:
        _target_: omnivision.meters.accuracy_meter.AccuracyMeter
        top_k: 5
  loss:
    _target_: torch.nn.CrossEntropyLoss
  optim:
    optimizer:
      _target_: torch.optim.SGD
      momentum: 0.9
      nesterov: True
      lr: 0.0
      weight_decay: 0.0
    options:
      lr:
        - scheduler:
            _target_: fvcore.common.param_scheduler.CosineParamScheduler
            start_value: 0.003125 # args.lr * int(args.batch_size / utils.get_world_size()) / 256 
            end_value: 0.0
          param_names:
            - '*head*'

lightning_trainer:
  _target_: pytorch_lightning.Trainer
  num_nodes: ${launcher.num_nodes}
  gpus: ${launcher.gpus_per_node}
  log_gpu_memory: null
  sync_batchnorm: False
  replace_sampler_ddp: False
  # limit_train_batches: 2
  # limit_val_batches: 10
  # limit_test_batches: 0
  max_epochs: 90
  accelerator: ${launcher.accelerator}
  strategy: ${launcher.strategy}

launcher:
  num_nodes: 2
  gpus_per_node: 8
  mode: train
  accelerator: gpu
  strategy: ddp

