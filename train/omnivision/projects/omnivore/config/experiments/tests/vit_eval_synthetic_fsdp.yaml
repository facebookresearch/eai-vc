# @package _global_

variables:
  path_to_checkpoint: /checkpoint/qduval/omnivision_omnivore/vit_train_synthetic_fsdp/2022-09-12-14:43:30/checkpoints/checkpoint.pt

trainer:
  _target_: omnivore.trainer.omnivision_trainer.OmnivisionTrainer
  max_epochs: 1
  mode: val
  accelerator: cuda
  seed_value: 123
  val_epoch_freq: 1
  strategy: fsdp

  logging:
    tensorboard_writer:
      _target_: omnivore.logger.make_tensorboard_logger
      log_dir:  ${launcher.experiment_log_dir}/tensorboard
      flush_secs: 120
    log_dir: ${launcher.experiment_log_dir}/logs
    log_freq: 10

  distributed:
   backend: nccl

  checkpoint:
    save_dir: ${launcher.experiment_log_dir}/checkpoints
    save_freq: 1 # 0 only last checkpoint is saved.
    model_weight_initializer:
      _partial_: True
      _target_: omnivore.models.fsdp_model_utils.load_state_dict_into_fsdp_model
      path_list:
        - ${variables.path_to_checkpoint}
      ckpt_state_dict_keys: ["model"]

  limit_train_batches: NULL
  limit_val_batches: NULL
  env_variables: NULL

  cuda:
    # https://pytorch.org/docs/stable/backends.html
    allow_tf32: False
    cudnn_deterministic: False
    cudnn_benchmark: True

  data:
    train: NULL
    val:
      _target_: omnivore.data.torch_dataset.TorchDataset
      dataset:
        _target_: omnivore.data.synthetic_dataset.SyntheticVisionSampleDataset
        visual_tensor_shape: [3, 224, 224]
        length: 1000
        num_classes: 10
        transforms:
          - _target_: omnivore.data.transforms.transform_wrappers.VisionTransform
            base_transform:
              _target_: torchvision.transforms.Compose
              transforms:
                - _target_: torchvision.transforms.CenterCrop
                  size: 224
                - _target_: torchvision.transforms.ToTensor
                - _target_: torchvision.transforms.RandomErasing
                  p: .25
                - _target_: torchvision.transforms.Normalize
                  mean: [0.485, 0.456, 0.406]
                  std: [0.229, 0.224, 0.225]
      shuffle: False
      batch_size: 64
      num_workers: 8
      pin_memory: True
      drop_last: True
      collate_fn:
        _target_: omnivore.data.api.DefaultOmnivoreCollator
        output_key: synth_image
      worker_init_fn: NULL

  model:
    _target_: omnivision.model.model_wrappers.MIMOHeadWrapper
    trunk:
      _target_: omnivore.models.vision_transformer.VisionTransformer
      fsdp_settings: ${trainer.fsdp_settings}
      attn_target:
        _target_: omnivore.models.vision_transformer.Attention
        _partial_: True
        num_heads: 12
        proj_drop: 0
        qk_scale: NULL
        qkv_bias: True
        attn_drop: 0
    heads:
      - head:
          _target_: omnivision.model.model_init_utils.init_parameters
          model:
            _target_: torch.nn.Linear
            in_features: 768  # 8 * 96
            out_features: 1000
          init_fns:
            weight:
              _target_: torch.nn.init.normal_
              _partial_: True
              mean: 0
              std: 0.01
            bias:
              _target_: torch.nn.init.zeros_
              _partial_: True
        fork_module: ""
        input_key: NULL
        output_key: NULL
    trunk_fields:
      - input_key: NULL
        args: ["vision"]
  fsdp_settings:
    _target_: omnivore.models.fsdp_model_utils.FSDPSettings
    flatten_parameters: false  # Set to false to match parameters by name
    move_params_to_cpu: false
    bucket_cap_mb: 0
    compute_dtype: float32
    mixed_precision: false
    fp32_reduce_scatter: false
    full_precision_layers:
      - torch.nn.LayerNorm
      - torch.nn.Softmax
  optim:
    gradient_clip:
      _target_: omnivore.optim.helpers.GradientClipper
      max_norm: 1.0
      norm_type: 2
    amp:
      enabled: false
      amp_dtype: float16 # bfloat16 or float16
    optimizer:
      _target_: torch.optim.AdamW
    options:
      lr:
        - scheduler:
            _target_: fvcore.common.param_scheduler.CompositeParamScheduler
            schedulers:
              - _target_: fvcore.common.param_scheduler.LinearParamScheduler
                start_value: 10e-7
                end_value: 10e-4
              - _target_: fvcore.common.param_scheduler.CosineParamScheduler
                start_value: 10e-4
                end_value: 10e-6
            lengths: [0.07, 0.93]
            interval_scaling: ['rescaled', 'rescaled']
      weight_decay:
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.05
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.0
          param_names:
             - '*.bias'
          module_cls_names: ['torch.nn.LayerNorm']
  meters:
    train:
      synth_image:
        accuracy_top1:
          _target_: omnivision.meters.accuracy_meter.AccuracyMeter
          top_k: 1
        accuracy_top5:
          _target_: omnivision.meters.accuracy_meter.AccuracyMeter
          top_k: 5
    val:
      synth_image:
        accuracy_top1:
          _target_: omnivision.meters.accuracy_meter.AccuracyMeter
          top_k: 1
        accuracy_top5:
          _target_: omnivision.meters.accuracy_meter.AccuracyMeter
          top_k: 5
  loss:
    synth_image:
      _target_: torch.nn.CrossEntropyLoss


launcher:
  num_nodes: 1
  gpus_per_node: 2
  experiment_log_dir: ???


hydra:
  output_subdir: NULL
  run:
    dir: .
