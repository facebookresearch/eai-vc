# @package _global_

defaults:
  - /experiments/imisra/085_simpletx_nomask_vitb32_laion21M_sunrgbdisp50x_imval_srgbdval_linheads_eqbatch_dispmaxnorm_detachrgb_ep32
out_dim: 512

trainer:
  data:
    train:
      _target_: omnivore.data.concat_dataset.ConcatDataset
      max_steps: sum
      repeat_factors: [1.0, 50.0]
      datasets:
      - _target_: omnivore.data.webdataset_helpers.WebVisionDatasetBatchedWithLoader
        base_dataset_fn:
          _target_: omnivore.data.webdataset_helpers.get_wds_dataset_batched
          _partial_: True
          urls:
            _target_: omnivore.utils.data.FileLoader.load
            return_idx: False
            path_list:
              - /checkpoint/imisra/datasets/laion/laion400m_subset21M_tarlist.pkl
          dataset_size_file: /checkpoint/imisra/datasets/laion/laion400m_subset21M_tarlist_numfiles.npy
          batch_size: ${constants.batch_size}
          num_workers: 12
          preprocess_txt:
            _target_: slip.tokenizer.SimpleTokenizer
            bpe_path_list: ${constants.bpe_path_list}
          preprocess_img:
            _target_: torchvision.transforms.Compose
            transforms:
              - _target_: torchvision.transforms.RandomResizedCrop
                size: 224
                interpolation: 3
                scale: [0.9, 1.0]
              - _target_: omnivore.data.transforms.basic.PILToRGB
              - _target_: torchvision.transforms.ToTensor
              - _target_: torchvision.transforms.Normalize
                mean: [0.485, 0.456, 0.406]
                std: [0.229, 0.224, 0.225]
        base_loader_fn:
          _target_: omnivore.data.webdataset_helpers.get_wds_loader
          num_workers: ${..base_dataset_fn.num_workers}
          collate_fn:
            _target_: omnivore.data.webdataset_helpers.BatchToSampleText
            collate_fn:
              _target_: omnivore.data.api.DefaultOmnivoreCollator
              output_key: laion
              batch_kwargs:
                model_fwd_kwargs:
                  use_checkpoint: true
              input_batch_is_collated: True
          _partial_: True
      - _target_: omnivore.data.torch_dataset.TorchDataset
        dataset:
          _target_: omnivore.data.path_dataset.ImageWithDepthPathDataset
          concatenate_depth_and_rgb_channels: False
          copy_on_read: True
          copy_on_read_dst_basename: ${..collate_fn.output_key}
          path_file_list:
            - /fsx-omnivore/imisra/datasets/sunrgbd/label_files/train_image_names.npy # AWS
            - /checkpoint/kalyanv/data/sunrgbd/train_image_names.npy
            - manifold://omnivore/tree/datasets/sunrgbd/scene_challenge/train_image_names.npy
          label_file_list:
            - /fsx-omnivore/imisra/datasets/sunrgbd/label_files/train_labels.npy # AWS
            - /checkpoint/kalyanv/data/sunrgbd/train_labels.npy
            - manifold://omnivore/tree/datasets/sunrgbd/scene_challenge/train_labels.npy
          depth_path_file_list:
            - /fsx-omnivore/imisra/datasets/sunrgbd/label_files/train_disparity_names.npy # AWS
            - /checkpoint/imisra/datasets/sunrgbd/label_files/train_disparity_names.npy
            - manifold://omnivore/tree/datasets/sunrgbd/scene_challenge/train_disparity_names.npy
          new_prefix: ${constants.sun_rgb_prefix}
          new_depth_prefix: ${constants.sun_depth_prefix}
          transforms:
            - _target_: omnivore.data.transforms.image_rgbd_sample.VisionDepthConcatChannelTransform
              base_transform:
                _target_: torchvision.transforms.Compose
                transforms:
                  - _target_: omnivore.data.transforms.image_rgbd.DepthNorm
                    max_depth: 75
                    clamp_max_before_scale: True
                  - _target_: torchvision.transforms.RandomResizedCrop
                    size: 224
                    interpolation: 2
                  - _target_: torchvision.transforms.RandomHorizontalFlip
                  - _target_: omnivore.data.transforms.image_rgbd.RandAugment3d  # Essentially autoagument rand-m9-mstd0.5-inc1
                    num_ops: 2
                    magnitude: 9
                    interpolation: 2
                  - _target_: omnivore.data.transforms.image_rgbd.ColorJitter3d
                    brightness: 0.4
                    contrast: 0.4
                    saturation: 0.4
                    hue: 0.4
                  - _target_: torchvision.transforms.RandomErasing
                    p: .25
                  - _target_: torchvision.transforms.Normalize
                    mean: [0.485, 0.456, 0.406, 0.0422]
                    std: [0.229, 0.224, 0.225, 0.01744]
        shuffle: True
        batch_size: ${constants.batch_size}
        num_workers: 12
        pin_memory: False
        drop_last: True
        collate_fn:
          _target_: omnivore.data.api.DefaultOmnivoreCollator
          output_key: sunrgbd
          batch_kwargs:
            model_fwd_kwargs:
              use_checkpoint: true         
          batch_transforms:
          - _target_: omnivore.data.transforms.image_rgbd_sample.VisionDepthConcatChannelToVisionDepthBatch
        worker_init_fn: NULL

  model:
    multimodal_model:
      trunks:
        - name: vision
          trunk:
            _target_: omnivore.models.simple_transformer.SimpleTransformer
            embed_dim: 1024
            num_blocks: 24
            ffn_dropout_rate: 0.0
            drop_path_rate: 0.0 # OpenCLIP
            layer_scale_type: per_channel
            layer_scale_init_value: 0.0001
            attn_target:
              _target_: omnivore.models.simple_transformer.MultiheadAttention
              embed_dim: ${..embed_dim}
              num_heads: 16
              dropout: 0.0
              bias: True
              add_bias_kv: True
              _partial_: True
            pre_transformer_layer:
              _target_: omnivore.models.helpers.EinOpsRearrange
              rearrange_expr: "b l d -> l b d"
            post_transformer_layer:
              _target_: omnivore.models.helpers.EinOpsRearrange
              rearrange_expr: "l b d -> b l d"
      postprocessors:
          - name: "normalize"
            postprocessor:
              _target_: omnivore.models.helpers.NormalizeAndCenter
              dim: -1
              out_features: ${out_dim}
          - name: "normalize_and_scale_text"
            postprocessor:
              _target_: torch.nn.Sequential
              _args_:
                - _target_: omnivore.models.helpers.NormalizeAndCenter
                  dim: -1
                  out_features: ${out_dim}
                - _target_: omnivore.models.helpers.LearnableLogitScaling
          - name: "normalize_and_scale_depth"
            postprocessor:
              _target_: torch.nn.Sequential
              _args_:
                - _target_: omnivore.models.helpers.NormalizeAndCenter
                  dim: -1
                  out_features: ${out_dim}
                - _target_: omnivore.models.helpers.LearnableLogitScaling
                  logit_scale_init: 10 # 1/0.1 as in SimCLR
                  learnable: False
  optim:
    optimizer:
      _target_: torch.optim.AdamW
      betas:
        - 0.9
        - 0.98
      eps: 1e-6
    options:
      lr:
        - scheduler:
            _target_: fvcore.common.param_scheduler.CompositeParamScheduler
            schedulers:
              - _target_: fvcore.common.param_scheduler.LinearParamScheduler
                start_value: 1e-6
                end_value: 1e-3
              - _target_: fvcore.common.param_scheduler.CosineParamScheduler
                start_value: ${..0.end_value}
                end_value: 1e-5
            lengths:
              - ${divide:${constants.warmup_epochs},${trainer.max_epochs}}
              - ${subtract:1,${divide:${constants.warmup_epochs},${trainer.max_epochs}}}
            interval_scaling: ['rescaled', 'rescaled']
      weight_decay:
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.05
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.0
          param_names:
            - '*.bias'
            - '*pos_embed'
            - '*cls_token'
            - "*log_logit_scale"
          module_cls_names: ["torch.nn.LayerNorm"]
constants:
  batch_size: 64
  kernel_size: 14
  sun_rgb_prefix: /fsx-omnivore/imisra/datasets/sunrgbd/images/
  sun_depth_prefix: /fsx-omnivore/imisra/datasets/sunrgbd/images_disparity/
  # sun_rgb_prefix: /checkpoint/kalyanv/data/sunrgbd/images/
  # sun_depth_prefix: /checkpoint/kalyanv/data/sunrgbd/images/

launcher:
  num_nodes: 8
  gpus_per_node: 8
